{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_sentence_count(df, text_col='clean_text', count_col=['doc_id'], grouped_by=[], time_col='dt',\n",
    "                           time_bin=None,start_time = None,end_time = None):\n",
    "    if len(df) == 0:\n",
    "        _df = df.copy()\n",
    "        return df\n",
    "\n",
    "    if isinstance(start_time,type(None)):\n",
    "        start_time = df[time_col].min()\n",
    "    if isinstance(end_time,type(None)):\n",
    "        end_time = df[time_col].max()\n",
    "\n",
    "\n",
    "    if isinstance(time_bin, type(None)):\n",
    "        bins = [start_time, end_time + pd.DateOffset(seconds=1)]\n",
    "\n",
    "    else:\n",
    "        timed, timet = int(time_bin[:-1]), time_bin[-1]\n",
    "        if timet == 'D':\n",
    "            dt = pd.DateOffset(days=timed)\n",
    "            start_time = pd.Timestamp('{}/{}/{}'.format(start_time.year, start_time.month, start_time.day))\n",
    "\n",
    "        elif timet == 'M':\n",
    "            dt = pd.DateOffset(months=timed)\n",
    "            start_time = pd.Timestamp('{}/{}/{}'.format(start_time.year, start_time.month, 1))\n",
    "        elif timet == 'Y':\n",
    "            dt = pd.DateOffset(months=timed)\n",
    "            start_time = pd.Timestamp('{}/{}/{}'.format(start_time.year, 1, 1))\n",
    "        else:\n",
    "            raise Error('invalid syntax for time bin')\n",
    "\n",
    "        bins = []\n",
    "        while start_time <= end_time:\n",
    "            bins.append(start_time)\n",
    "            start_time += dt\n",
    "        bins.append(start_time)\n",
    "\n",
    "    _df = df.copy()\n",
    "    _df['dt_bin'] = pd.cut(_df['dt'], bins, labels=None, right=False)\n",
    "\n",
    "    grouped_by.append('dt_bin')\n",
    "\n",
    "    col_to_keep = [text_col] + count_col + grouped_by\n",
    "    _df = _df[col_to_keep].drop_duplicates()[[text_col] + grouped_by]\n",
    "    _df = _df.groupby(grouped_by)[text_col].value_counts().rename(\n",
    "        'count_{}_by_{}'.format(\",\".join(count_col), \",\".join(grouped_by))).reset_index()\n",
    "\n",
    "    _df['dt_bin_l'] = _df['dt_bin'].apply(lambda x : x.left)\n",
    "    _df['dt_bin_r'] = _df['dt_bin'].apply(lambda x : x.right)\n",
    "    _df = _df.drop(columns = ['dt_bin'])\n",
    "\n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "def aggregate_over_time(dfs, time_intervals, time_bin_cols=['dt_bin_l','dt_bin_r']):\n",
    "    _dfs_in_time = []\n",
    "\n",
    "    def aux(i, i_list):\n",
    "        return [x for x in i_list if i.overlaps(x)]\n",
    "\n",
    "    time_frames = pd.Series(time_intervals).astype(object).rename('time_frames')\n",
    "\n",
    "    for df in dfs:\n",
    "        _df = df.copy()\n",
    "        s_time_bin_l = list(_df[time_bin_cols[0]].cat.categories)\n",
    "        s_time_bin_r = list(_df[time_bin_cols[1]].cat.categories)\n",
    "        s_time_bin = [pd.Interval(s_time_bin_l[k],s_time_bin_r[k],closed = 'left') for k in range(len(s_time_bin_r))]\n",
    "        \n",
    "        r = time_frames.apply(lambda x: aux(x, s_time_bin))\n",
    "        r = pd.DataFrame(r.tolist()).stack().reset_index().drop(columns=['level_1']).set_index('level_0')\n",
    "        r.columns = [time_bin_cols[0]]\n",
    "        r[time_bin_cols[0]] =  r[time_bin_cols[0]].apply(lambda x : x.left)\n",
    "        r = r.join(time_frames)\n",
    "        _df[time_bin_cols[0]] =  _df[time_bin_cols[0]].astype(datetime64[ns])\n",
    "        r = pd.merge(r, _df, on=[time_bin_cols[0]]).drop(columns=time_bin_cols)\n",
    "        _dfs_in_time.append(r)\n",
    "    return pd.concat(_dfs_in_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_sentence_count(df, sentence_col='clean_sentence', dfs_count=None, time_col='dt', freq='1M',\n",
    "                        window='2Y',dfs_count_time_bin_cols = ['dt_bin_l','dt_bin_r']):\n",
    "    # First of all, bin the data frame\n",
    "    _df = df.copy()\n",
    "\n",
    "    min_time = df[time_col].min()\n",
    "    start_time = min_time\n",
    "    end_time = df[time_col].max()\n",
    "\n",
    "    if isinstance(freq, type(None)):\n",
    "        freq = end_time - start_time + pd.Timedelta(seconds=1)\n",
    "\n",
    "    else:\n",
    "        time_scale = freq[-1]\n",
    "        freq = int(freq[:-1])\n",
    "        if time_scale == 'D':\n",
    "            freq = pd.DateOffset(days=freq)\n",
    "            start_time = pd.Timestamp('{}/{}/{}'.format(start_time.year, start_time.month, start_time.day))\n",
    "        elif time_scale == 'M':\n",
    "            freq = pd.DateOffset(months=freq)\n",
    "            start_time = pd.Timestamp('{}/{}/01'.format(start_time.year, start_time.month))\n",
    "        elif time_scale == 'Y':\n",
    "            freq = pd.DateOffset(years=freq)\n",
    "            start_time = pd.Timestamp('{}/01/01'.format(start_time.year))\n",
    "        else:\n",
    "            raise Error('invalid syntax for frequency')\n",
    "\n",
    "    time_bins = []\n",
    "    while start_time <= end_time:\n",
    "        time_bins.append(start_time)\n",
    "        start_time += freq\n",
    "    time_bins.append(start_time)\n",
    "\n",
    "    _df['time_frame'] = pd.cut(_df['dt'], time_bins, labels=None, right=False)\n",
    "\n",
    "    if not (isinstance(window, type(None))):\n",
    "        time_scale = window[-1]\n",
    "        window = int(window[:-1])\n",
    "        if time_scale == 'D':\n",
    "            window = pd.DateOffset(days=window)\n",
    "        elif time_scale == 'M':\n",
    "            window = pd.DateOffset(months=window)\n",
    "        elif time_scale == 'Y':\n",
    "            window = pd.DateOffset(years=window)\n",
    "        else:\n",
    "            raise Error('invalid syntax for window')\n",
    "\n",
    "    def aux_find_start_time(interval):\n",
    "        if isinstance(window, type(None)):\n",
    "            return pd.Interval(min_time, interval.right, closed='left')\n",
    "        else:\n",
    "            return pd.Interval(interval.right - window, interval.right, closed='left')\n",
    "\n",
    "    _df['time_frame'] = _df['time_frame'].apply(aux_find_start_time)\n",
    "\n",
    "    time_frames = list(_df['time_frame'].cat.categories)\n",
    "\n",
    "    aux = aggregate_over_time(dfs_count, time_frames, time_bin_cols=dfs_count_time_bin_cols).groupby(\n",
    "        ['time_frame', sentence_col]).sum().reset_index()\n",
    "    aux.columns = ['time_frame', sentence_col, 'count']\n",
    "\n",
    "\n",
    "    _df = pd.merge(aux, _df, how='right', on=['time_frame', sentence_col]).drop(columns=['time_frame'])\n",
    "    _df = _df.fillna(1)\n",
    "    _df['count'] = _df['count'].astype(int)\n",
    "    return _df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
